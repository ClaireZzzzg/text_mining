{"cells":[{"cell_type":"markdown","metadata":{"id":"4HxZwv2Z-OX5"},"source":["## VECTORIZATION TECHNIQUES"]},{"cell_type":"markdown","metadata":{"id":"3tUYy5Yo-OX6"},"source":["Text vectorization is the process of feature extraction from text data, that is the process of creating variables for each observation, where an observation is a text document. We'll consider the **bag-of-words**, the **TF-IDF** and the **n-grams** vectorized representations of text. <br>\n","\n","Let's vectorize the corpus about \"blue skies and blue cheese\" similar to one used in the video lecture: "]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1es07270-OX6"},"outputs":[],"source":["corpus = ['the sky is blue',\n","          'sky is blue and sky is beautiful', \n","          'the beautiful sky is so blue',\n","          'i love blue cheese']"]},{"cell_type":"markdown","metadata":{"id":"fZNw2dzc-OX6"},"source":["We'll use built-in vectorizers from Scikit-Learn module for machine learning. "]},{"cell_type":"markdown","metadata":{"id":"5AbVrZT2-OX6"},"source":["### Bag-of-Words Representation\n","\n","We'll use bag-of-words representation (CountVectorizer) first. You can see the documentation here:\n","https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"VJlZj8RN-OX6"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","vectorizer_BOW = CountVectorizer(max_features=1000) #\"define\" a vectorizer\n","BOW_matrix = vectorizer_BOW.fit_transform(corpus).toarray() #Note the .fit_transform function below. It creates the dictionary of the corpus and does the vectorization: \n","pd.DataFrame(np.round(BOW_matrix,2),columns=vectorizer_BOW.get_feature_names()) #Here are the names of the features from the dictionary of the corpus"]},{"cell_type":"markdown","metadata":{"id":"io0YSTri-OX8"},"source":["### Vectorization Using N-grams\n","<br>"]},{"cell_type":"markdown","metadata":{},"source":["ngram_rangetuple (min_n, max_n), default=(1, 1)\n","The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n <= n <= max_n will be used. For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"elapsed":108,"status":"ok","timestamp":1648584954026,"user":{"displayName":"Claire Z.","userId":"15310629086553932750"},"user_tz":300},"id":"g5vT71xA-OX8","outputId":"dfb9f98a-73bd-4db0-a6f2-8b3e17404a52"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>and sky</th>\n","      <th>beautiful sky</th>\n","      <th>blue and</th>\n","      <th>blue cheese</th>\n","      <th>is beautiful</th>\n","      <th>is blue</th>\n","      <th>is so</th>\n","      <th>love blue</th>\n","      <th>sky is</th>\n","      <th>so blue</th>\n","      <th>the beautiful</th>\n","      <th>the sky</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   and sky  beautiful sky  blue and  blue cheese  is beautiful  is blue  \\\n","0        0              0         0            0             0        1   \n","1        1              0         1            0             1        1   \n","2        0              1         0            0             0        0   \n","3        0              0         0            1             0        0   \n","\n","   is so  love blue  sky is  so blue  the beautiful  the sky  \n","0      0          0       1        0              0        1  \n","1      0          0       2        0              0        0  \n","2      1          0       1        1              1        0  \n","3      0          1       0        0              0        0  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["vectorizer_Bi_Grams = CountVectorizer(max_features=1000, ngram_range=(2, 2))\n","Bi_Grams_matrix = vectorizer_Bi_Grams.fit_transform(corpus).toarray()\n","pd.DataFrame(np.round(Bi_Grams_matrix,2),columns=vectorizer_Bi_Grams.get_feature_names())"]},{"cell_type":"markdown","metadata":{"id":"VM6IRfwJ-OX9"},"source":["### Vectorization with Term Frequency â€“ Inverse Document Frequency (TF-IDF)\n","\n","Now, let's do feature extraction (vectorization) using the TF-IDF approach. <br> <br> See full documentation here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer <br> <br>\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"NMQS2XcT-OX9"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer \n","\n","vectorizer_TF_IDF = TfidfVectorizer(norm = None, smooth_idf = True)\n","TF_IDF_matrix = vectorizer_TF_IDF.fit_transform(corpus).toarray()\n","pd.DataFrame(np.round(TF_IDF_matrix, 2), columns=vectorizer_TF_IDF.get_feature_names())"]},{"cell_type":"markdown","metadata":{"id":"gu4G919s-OX9"},"source":["Have a look at the IDF weights:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102,"status":"ok","timestamp":1648585374955,"user":{"displayName":"Claire Z.","userId":"15310629086553932750"},"user_tz":300},"id":"_xQwCOJw-OX9","outputId":"1739e353-ecbd-4d69-ea3c-698d1b072e98"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.92 1.51 1.   1.92 1.22 1.92 1.22 1.92 1.51]\n"]}],"source":["print(np.round(vectorizer_TF_IDF.idf_,2))"]},{"cell_type":"markdown","metadata":{"id":"ICCU3Dli-OX9"},"source":["It's a good idea to normalize the TF-IDF matrix, i.e. restrict all entries to be between 0 and 1. Some text mining models require normalized matrices. Norm parameter is used for this purpose (you can look it up in the documentation):"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"elapsed":125,"status":"ok","timestamp":1648585589102,"user":{"displayName":"Claire Z.","userId":"15310629086553932750"},"user_tz":300},"id":"bz4bFsUG-OX-","outputId":"d5b801b7-a347-4c2b-de63-a1b686b5f2da"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>and</th>\n","      <th>beautiful</th>\n","      <th>blue</th>\n","      <th>cheese</th>\n","      <th>is</th>\n","      <th>love</th>\n","      <th>sky</th>\n","      <th>so</th>\n","      <th>the</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.40</td>\n","      <td>0.00</td>\n","      <td>0.49</td>\n","      <td>0.00</td>\n","      <td>0.49</td>\n","      <td>0.00</td>\n","      <td>0.60</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.44</td>\n","      <td>0.35</td>\n","      <td>0.23</td>\n","      <td>0.00</td>\n","      <td>0.56</td>\n","      <td>0.00</td>\n","      <td>0.56</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.00</td>\n","      <td>0.43</td>\n","      <td>0.29</td>\n","      <td>0.00</td>\n","      <td>0.35</td>\n","      <td>0.00</td>\n","      <td>0.35</td>\n","      <td>0.55</td>\n","      <td>0.43</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.35</td>\n","      <td>0.66</td>\n","      <td>0.00</td>\n","      <td>0.66</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    and  beautiful  blue  cheese    is  love   sky    so   the\n","0  0.00       0.00  0.40    0.00  0.49  0.00  0.49  0.00  0.60\n","1  0.44       0.35  0.23    0.00  0.56  0.00  0.56  0.00  0.00\n","2  0.00       0.43  0.29    0.00  0.35  0.00  0.35  0.55  0.43\n","3  0.00       0.00  0.35    0.66  0.00  0.66  0.00  0.00  0.00"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["vectorizer_TF_IDF = TfidfVectorizer(norm = 'l2', smooth_idf = True)\n","TF_IDF_matrix = vectorizer_TF_IDF.fit_transform(corpus).todense()\n","pd.DataFrame(np.round(TF_IDF_matrix,2), columns=vectorizer_TF_IDF.get_feature_names())"]},{"cell_type":"markdown","metadata":{"id":"ItXe9YGf-OX-"},"source":["### **<font color=green> EXERCISE 3: You are given a new small corpus called corpus_exercise (see below). Your ultimate task is to normalize (pre-process) the corpus and produce the TF-IDF and the Bag-of-Words representations of the data. Follow the steps below to complete this exercise:</font>**"]},{"cell_type":"markdown","metadata":{"id":"TX7snDM0-OX-"},"source":["Step 1. Download a file Text_Normalization_Function.ipynb from Canvas and put it into the same directory(!) as the current Jupyter notebook. That file defines a relatively sophisticated text normalization function. (OPTIONAL: you can explore what that file does when you are done with this exercise.)"]},{"cell_type":"markdown","metadata":{"id":"bo2LYLCn-OX-"},"source":["Step 2. Run the file Text_Normalization_Function.ipynb to define the text normalization function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gGPNa2G-OX-"},"outputs":[],"source":["%run ./Text_Normalization_Function.ipynb"]},{"cell_type":"markdown","metadata":{"id":"SluD2Ev--OX-"},"source":["Step 3. Define the corpus_exercise text corpus:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJeshMYw-OX-"},"outputs":[],"source":["corpus_exercise = ['python is great for text mining',\n","          'anyone can learn python and do text mining', \n","          'python can go without eating for days',\n","          'python can be a great pet']"]},{"cell_type":"markdown","metadata":{"id":"5Z9c4gLK-OX_"},"source":["Step 4. Normalize the corpus_exercise text corpus and call its normalized version NORM_corpus:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93,"status":"ok","timestamp":1648585705191,"user":{"displayName":"Claire Z.","userId":"15310629086553932750"},"user_tz":300},"id":"edbM-_Hj-OX_","outputId":"0b412a0d-85e5-42fa-ba55-9c365640c410"},"outputs":[{"data":{"text/plain":["['python great text mining',\n"," 'anyone learn python text mining',\n"," 'python without eat day',\n"," 'python great pet']"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["NORM_corpus = normalize_corpus(corpus_exercise)\n","NORM_corpus"]},{"cell_type":"markdown","metadata":{"id":"EVuG8bXj-OX_"},"source":["Step 5. Compute and print out the TF-IDF and the Bag-of-Words representations for NORM_corpus (WRITE the lines of code needed in the cell below):"]},{"cell_type":"markdown","metadata":{"id":"mz_PqkBm-OX_"},"source":["### <font color=green> Answer for E3:"]},{"cell_type":"markdown","metadata":{"id":"dCEpmlj0-OX_"},"source":["The bag-of-words representation of the normalized corpus (NORM_corpus):"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1648585923736,"user":{"displayName":"Claire Z.","userId":"15310629086553932750"},"user_tz":300},"id":"iDlSzq61-OX_","outputId":"a3df3e9b-c1bb-4f36-cc4b-c04815590da0"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-b52122e5-8386-48a6-a7f1-4f135afe33f3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anyone</th>\n","      <th>day</th>\n","      <th>eat</th>\n","      <th>great</th>\n","      <th>learn</th>\n","      <th>mining</th>\n","      <th>pet</th>\n","      <th>python</th>\n","      <th>text</th>\n","      <th>without</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b52122e5-8386-48a6-a7f1-4f135afe33f3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b52122e5-8386-48a6-a7f1-4f135afe33f3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b52122e5-8386-48a6-a7f1-4f135afe33f3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   anyone  day  eat  great  learn  mining  pet  python  text  without\n","0       0    0    0      1      0       1    0       1     1        0\n","1       1    0    0      0      1       1    0       1     1        0\n","2       0    1    1      0      0       0    0       1     0        1\n","3       0    0    0      1      0       0    1       1     0        0"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["vectorizer_BOW = CountVectorizer(max_features=1000) #BOW = bag-of-words\n","BOW_matrix = vectorizer_BOW.fit_transform(NORM_corpus).toarray()\n","pd.DataFrame(np.round(BOW_matrix,2),columns=vectorizer_BOW.get_feature_names())"]},{"cell_type":"markdown","metadata":{"id":"Mz2W_hiB-OYA"},"source":["The TF-IDF representation of the corpus:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1648586126752,"user":{"displayName":"Claire Z.","userId":"15310629086553932750"},"user_tz":300},"id":"zYvqy9B--OYA","outputId":"a7819a43-9191-4f63-db44-45af0d3aa89a"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-e0e31aa0-6ee2-4789-b1f2-0156b398890e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anyone</th>\n","      <th>day</th>\n","      <th>eat</th>\n","      <th>great</th>\n","      <th>learn</th>\n","      <th>mining</th>\n","      <th>pet</th>\n","      <th>python</th>\n","      <th>text</th>\n","      <th>without</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.54</td>\n","      <td>0.00</td>\n","      <td>0.54</td>\n","      <td>0.00</td>\n","      <td>0.36</td>\n","      <td>0.54</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.53</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.53</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.28</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.00</td>\n","      <td>0.55</td>\n","      <td>0.55</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.29</td>\n","      <td>0.00</td>\n","      <td>0.55</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.57</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.73</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0e31aa0-6ee2-4789-b1f2-0156b398890e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e0e31aa0-6ee2-4789-b1f2-0156b398890e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e0e31aa0-6ee2-4789-b1f2-0156b398890e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   anyone   day   eat  great  learn  mining   pet  python  text  without\n","0    0.00  0.00  0.00   0.54   0.00    0.54  0.00    0.36  0.54     0.00\n","1    0.53  0.00  0.00   0.00   0.53    0.42  0.00    0.28  0.42     0.00\n","2    0.00  0.55  0.55   0.00   0.00    0.00  0.00    0.29  0.00     0.55\n","3    0.00  0.00  0.00   0.57   0.00    0.00  0.73    0.38  0.00     0.00"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["vectorizer_TF_IDF = TfidfVectorizer(norm = 'l2', smooth_idf = True)\n","TF_IDF_matrix = vectorizer_TF_IDF.fit_transform(NORM_corpus).todense()\n","pd.DataFrame(np.round(TF_IDF_matrix,2), columns=vectorizer_TF_IDF.get_feature_names())"]},{"cell_type":"markdown","metadata":{"id":"ijqHSdF5-OYA"},"source":["### <font color=green> End of Answer"]}],"metadata":{"colab":{"collapsed_sections":["cOtUSOgk-OX0","b7DEot9N-OX5","io0YSTri-OX8","oNPIe3cL-OX8","ijqHSdF5-OYA"],"name":"Lab_2_Normalization_and_Vectorization_S2022.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
